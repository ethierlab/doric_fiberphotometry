{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from ipywidgets import GridBox, Layout\n",
    "\n",
    "import fileselector as fs\n",
    "from importlib import reload\n",
    "reload(fs)\n",
    "fs.load_dependencies()\n",
    "# Usage\n",
    "# Replace '/your/start/directory/' with your actual start directory\n",
    "Path='/home/coder/project/doric_fiberphotometry/Data/knob'\n",
    "\n",
    "file_selector = fs.FileSelector(Path)\n",
    "# file_name = file_selector.get_selected_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After selecting datasets, the respective info will be displayed.\n",
    "## Then, click \"Load Data\" button to load the datasets.\n",
    "isos_df = file_selector.get_isos_df()\n",
    "grabda_df = file_selector.get_grabda_df()\n",
    "event_df = file_selector.get_event_df()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import dataexplorer as de\n",
    "from importlib import reload\n",
    "try:\n",
    "    import ipympl\n",
    "    print(\"ipympl is installed. You can proceed with %matplotlib ipympl.\")\n",
    "    %matplotlib widget\n",
    "except ImportError:\n",
    "    print(\"ipympl is not installed. Please run !pip install ipympl.\")\n",
    "    !pip install ipympl\n",
    "    %matplotlib widget\n",
    "\n",
    "\n",
    "reload(de)\n",
    "\n",
    "de.plot_and_save_seperated(isos_df, grabda_df, event_df,file_selector)\n",
    "\n",
    "de.plot_and_save(isos_df,grabda_df,event_df,file_selector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knob Events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataexplorer as de\n",
    "from importlib import reload\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "reload(de)\n",
    "\n",
    "rising_edges = event_df['Data'].diff() == 1\n",
    "rising_edge_df = event_df[rising_edges].reset_index().rename(columns={'index': 'Sample_Number'})\n",
    "## Calculate the optimal time window\n",
    "optimal_window = de.find_optimal_time_window(rising_edge_df,Event_type='Knob')\n",
    "print(\"optimal window is :\",optimal_window)\n",
    "## Classify events in the rising_edge_df\n",
    "# classified_events_df = de.classify_events(rising_edge_df,optimal_window,['Init','Success','Fail'])\n",
    "classified_events_df = de.classify_events(rising_edge_df,optimal_window,Event_type='knob')\n",
    "\n",
    "print(classified_events_df.head())\n",
    "print(\"Event Number: \",len(classified_events_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Use function get_zdFF to calculate z-dF/F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download photometry_functions.py file from [here](https://github.com/katemartian/Photometry_data_processing \"source\").\n",
    "\n",
    "please cite Jove paper:\n",
    "\n",
    "__Martianova, E., Aronson, S., Proulx, C.D.__ [Multi-Fiber Photometry to Record Neural Activity in Freely Moving Animal.](https://www.jove.com/video/60278/multi-fiber-photometry-to-record-neural-activity-freely-moving). _J. Vis. Exp._ (152), e60278, doi:10.3791/60278 (2019).\n",
    "\n",
    "[refrence](https://colab.research.google.com/github/katemartian/Photometry_data_processing/blob/master/Photometry_data_processing.ipynb#scrollTo=Lak9o-Hn3QQW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import photometry_functions as pf\n",
    "reload(pf)\n",
    "# Usage\n",
    "def save_signal(zdff):\n",
    "    global signal_df \n",
    "    signal_df = zdff\n",
    "    \n",
    "    print(signal_df.head())\n",
    "analysis = pf.PhotometryAnalysis(isos_df,grabda_df,save_signal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSTH Prepration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut and Center the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import photometry_functions as pf\n",
    "from importlib import reload\n",
    "\n",
    "reload(pf)\n",
    "\n",
    "# Example usage:\n",
    "time_window = (-4, 10)  # For example, 2 seconds before and after the event\n",
    "event_type = \"Init\"  # Use \"All\" to process all events, or specify a particular type like 'Init'\n",
    "centralized_signals_df_Init = pf.cut_and_center_signals_modified(signal_df, classified_events_df, time_window, event_type)\n",
    "print(centralized_signals_df_Init.head())\n",
    "\n",
    "event_type = \"Success\"  # Use \"All\" to process all events, or specify a particular type like 'Init'\n",
    "centralized_signals_df_Success = pf.cut_and_center_signals_modified(signal_df, classified_events_df, time_window, event_type)\n",
    "print(centralized_signals_df_Success.head())\n",
    "\n",
    "event_type = \"Fail\"  # Use \"All\" to process all events, or specify a particular type like 'Init'\n",
    "centralized_signals_df_Fail = pf.cut_and_center_signals_modified(signal_df, classified_events_df, time_window, event_type)\n",
    "print(centralized_signals_df_Fail.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want un centralized signals with init you can run this part if not skip this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "time_window = (-4, 10)  # For example, 2 seconds before and after the event\n",
    "event_type = \"Init\"  # Use \"All\" to process all events, or specify a particular type like 'Init'\n",
    "centralized_signals_df_Init = pf.cut_and_center_signals(signal_df, classified_events_df, time_window, event_type)\n",
    "print(centralized_signals_df_Init.head())\n",
    "\n",
    "event_type = \"Success\"  # Use \"All\" to process all events, or specify a particular type like 'Init'\n",
    "centralized_signals_df_Success = pf.cut_and_center_signals(signal_df, classified_events_df, time_window, event_type)\n",
    "print(centralized_signals_df_Success.head())\n",
    "\n",
    "event_type = \"Fail\"  # Use \"All\" to process all events, or specify a particular type like 'Init'\n",
    "centralized_signals_df_Fail = pf.cut_and_center_signals(signal_df, classified_events_df, time_window, event_type)\n",
    "print(centralized_signals_df_Fail.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all Signals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Plot All signals\n",
    "y_min = -2\n",
    "y_max = 4\n",
    "\n",
    "import photometry_functions as pf\n",
    "from importlib import reload\n",
    "reload(pf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Init:\n",
    "fig = plt\n",
    "pf.plot_cut_signals(centralized_signals_df_Init,y_min,y_max)\n",
    "# plot_cut_signals(filtered_signal_df)\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'/all_Inits.png'\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "fig.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n",
    "\n",
    "# Success:\n",
    "fig = plt\n",
    "pf.plot_cut_signals(centralized_signals_df_Success,y_min,y_max)\n",
    "# plot_cut_signals(filtered_signal_df)\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'/all_Success.png'\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "fig.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n",
    "\n",
    "# Fail:\n",
    "fig = plt\n",
    "pf.plot_cut_signals(centralized_signals_df_Fail,y_min,y_max)\n",
    "# plot_cut_signals(filtered_signal_df)\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'/all_Fails.png'\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "fig.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Signals seperatly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import photometry_functions as pf\n",
    "from importlib import reload\n",
    "\n",
    "reload(pf)\n",
    "\n",
    "# Init\n",
    "pf.plot_cut_signals_seperated(centralized_signals_df_Init,y_min,y_max)\n",
    "\n",
    "fig = plt\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'/Separeted_Init_Events.png'\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "fig.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n",
    "\n",
    "# Success\n",
    "pf.plot_cut_signals_seperated(centralized_signals_df_Success,y_min,y_max)\n",
    "\n",
    "fig = plt\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'/Separeted_Success_Events.png'\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "fig.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n",
    "\n",
    "# Fail\n",
    "pf.plot_cut_signals_seperated(centralized_signals_df_Fail,y_min,y_max)\n",
    "\n",
    "fig = plt\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'/Separeted_Fail_Events.png'\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "fig.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and Select Signals for PSTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import photometry_functions as pf\n",
    "from importlib import reload\n",
    "\n",
    "reload(pf)\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "def handle_filtered_data(df,event_type):\n",
    "    # Handle the filtered DataFrame here, e.g., save it to a global variable or process it further\n",
    "    if event_type == 'Init':    \n",
    "        global filtered_signal_df_Init\n",
    "        filtered_signal_df_Init = df\n",
    "        print(filtered_signal_df_Init.head())\n",
    "    \n",
    "    if event_type == 'Fail':    \n",
    "        global filtered_signal_df_Fail\n",
    "        filtered_signal_df_Fail = df\n",
    "        print(filtered_signal_df_Fail.head())\n",
    "    \n",
    "    if event_type == 'Success':    \n",
    "        global filtered_signal_df_Success\n",
    "        filtered_signal_df_Success = df\n",
    "        print(filtered_signal_df_Success.head())\n",
    "    \n",
    "    \n",
    "    fig = plt\n",
    "    filename = file_selector.file_path.split('.')[0]+'/Figs/'+'/Selected_Stim_Events_'+event_type+'.png'\n",
    "\n",
    "    directory = os.path.dirname(filename)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    fig.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Figure saved as {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "# Init:\n",
    "explorer = pf.SignalExplorer(centralized_signals_df_Init,'Init', save_callback=handle_filtered_data)\n",
    "# This will display the widgets and allow interaction\n",
    "\n",
    "# Success:\n",
    "explorer = pf.SignalExplorer(centralized_signals_df_Success,'Success', save_callback=handle_filtered_data)\n",
    "# This will display the widgets and allow interaction\n",
    "\n",
    "# Fail:\n",
    "explorer = pf.SignalExplorer(centralized_signals_df_Fail,'Fail', save_callback=handle_filtered_data)\n",
    "# This will display the widgets and allow interaction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import photometry_functions as pf\n",
    "from importlib import reload\n",
    "\n",
    "reload(pf)\n",
    "\n",
    "\n",
    "# Init:\n",
    "# Assuming 'Data' is the column in filtered_signal_df that you want to normalize\n",
    "normalized_signal_df_Init = pf.normalize_signal(filtered_signal_df_Init, column='Data')\n",
    "\n",
    "# Success:\n",
    "# Assuming 'Data' is the column in filtered_signal_df that you want to normalize\n",
    "normalized_signal_df_Success = pf.normalize_signal(filtered_signal_df_Success, column='Data')\n",
    "\n",
    "# Fail:\n",
    "# Assuming 'Data' is the column in filtered_signal_df that you want to normalize\n",
    "normalized_signal_df_Fail = pf.normalize_signal(filtered_signal_df_Fail, column='Data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This will normalize between -1 and 1 (not recomended to run it will incrupt the AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import photometry_functions as pf\n",
    "from importlib import reload\n",
    "\n",
    "reload(pf)\n",
    "\n",
    "# Init:\n",
    "# Assuming 'Data' is the column in filtered_signal_df that you want to normalize\n",
    "normalized_signal_df_Init2 = pf.normalize_signal2(normalized_signal_df_Init, column='Data')\n",
    "\n",
    "# Success:\n",
    "# Assuming 'Data' is the column in filtered_signal_df that you want to normalize\n",
    "normalized_signal_df_Success2 = pf.normalize_signal2(normalized_signal_df_Success, column='Data')\n",
    "\n",
    "# Fail:\n",
    "# Assuming 'Data' is the column in filtered_signal_df that you want to normalize\n",
    "normalized_signal_df_Fail2 = pf.normalize_signal2(normalized_signal_df_Fail, column='Data')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Resaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSTH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import photometry_functions as pf\n",
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "reload(pf)\n",
    "\n",
    "\n",
    "PSTH_df_Fail=pf.create_psth_with_min_max(normalized_signal_df_Fail)\n",
    "PSTH_df_Success=pf.create_psth_with_min_max(normalized_signal_df_Success)\n",
    "\n",
    "PSTH_df_std_Fail = pf.create_psth_with_std(normalized_signal_df_Fail)\n",
    "PSTH_df_std_Success = pf.create_psth_with_std(normalized_signal_df_Success)\n",
    "\n",
    "PSTH_df_ci_Fail = pf.create_psth_with_ci(normalized_signal_df_Fail)\n",
    "PSTH_df_ci_Success = pf.create_psth_with_ci(normalized_signal_df_Success)\n",
    "\n",
    "# Create a figure and a 3x1 grid of subplots\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "\n",
    "# PSTH_df_Init=pf.create_psth_with_min_max(normalized_signal_df_Init)\n",
    "# pf.plot_psth(PSTH_df_Init, -3, 3,'black','Init')\n",
    "pf.plot_psth(PSTH_df_ci_Fail, -3, 3,'black','Fail',pos=axs[2])\n",
    "pf.plot_psth(PSTH_df_ci_Success, -3, 3,'green','Success',pos=axs[2])\n",
    "\n",
    "\n",
    "pf.plot_psth(PSTH_df_std_Fail, -3, 3,'black','Fail',pos=axs[1])\n",
    "pf.plot_psth(PSTH_df_std_Success, -3, 3,'green','Success',pos=axs[1])\n",
    "# plt.subplots(2,2,2)\n",
    "\n",
    "pf.plot_psth(PSTH_df_Fail, -3, 3,'black','Fail',pos=axs[0])\n",
    "pf.plot_psth(PSTH_df_Success, -3, 3,'green','Success',pos=axs[0])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'PSTH.png'\n",
    "\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "fig.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import photometry_functions as pf\n",
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "reload(pf)\n",
    "\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'/Heatmap_init.png'\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "\n",
    "pf.heatmap_plot(normalized_signal_df_Init)\n",
    "plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n",
    "\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'/Heatmap_Fail.png'\n",
    "pf.heatmap_plot(normalized_signal_df_Fail)\n",
    "plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n",
    "\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'/Heatmap_Success.png'\n",
    "pf.heatmap_plot(normalized_signal_df_Success)\n",
    "plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under Curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import photometry_functions as pf\n",
    "import fileselector as fs\n",
    "import os\n",
    "from importlib import reload\n",
    "reload(fs)\n",
    "reload(pf)\n",
    "fs.load_dependencies()\n",
    "\n",
    "# Success\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "pf.plot_psth_auc(PSTH_df_std_Success,-2, 3.5,'green','Stim')\n",
    "plt.show()\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'AUC_Success.png'\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n",
    "\n",
    "pf.plot_auc_bars_with_duration(PSTH_df_std_Success,-0.1, 0.1,(-2,0),(0,3))\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'AUC_Bars_Success.png'\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n",
    "\n",
    "# Fail\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "pf.plot_psth_auc(PSTH_df_std_Fail,-2, 3.5,'green','Stim')\n",
    "plt.show()\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'AUC_Fail.png'\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n",
    "\n",
    "pf.plot_auc_bars_with_duration(PSTH_df_std_Fail,-0.1, 0.1,(-2,0),(0,3))\n",
    "filename = file_selector.file_path.split('.')[0]+'/Figs/'+'AUC_Bars_Fail.png'\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved as {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving all the Dataframes as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def save_dataframes_to_csv():\n",
    "    # Fetch the current datetime to append to file names to avoid overwriting\n",
    "    now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = file_selector.file_path.split('.')[0]+'/Data/'+'test.csv\"'\n",
    "    directory = os.path.dirname(filename)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    # Loop through all global variables\n",
    "    for var_name, value in list(globals().items()):\n",
    "        # Check if the value is an instance of pd.DataFrame\n",
    "        if isinstance(value, pd.DataFrame):\n",
    "            # Construct filename with a timestamp to prevent overwriting\n",
    "            file = f\"{var_name}_{now}.csv\"\n",
    "            filename = file_selector.file_path.split('.')[0]+'/Data/'+file\n",
    "\n",
    "            # Save the DataFrame to a CSV file\n",
    "            value.to_csv(filename, index=False)\n",
    "            print(f\"Saved {filename}\")\n",
    "\n",
    "\n",
    "# Call the function to save all DataFrames\n",
    "save_dataframes_to_csv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reloading saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_dataframe_from_csv(file_path):\n",
    "    \"\"\"\n",
    "    Loads a DataFrame from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the CSV file to be loaded.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame containing the data from the CSV file.\n",
    "    \"\"\"\n",
    "    # Loading the DataFrame from the specified CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'your_file.csv' with the path to the CSV file you want to load\n",
    "\n",
    "csv_file_path = 'your_file.csv'\n",
    "df = load_dataframe_from_csv(csv_file_path)\n",
    "# Optionally, you can display the first few rows of the loaded DataFrame\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
